{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "093678c3",
   "metadata": {},
   "source": [
    "## Describe data: A dive into visualizing data distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8f2a59",
   "metadata": {},
   "source": [
    "### Learning goals\n",
    "\n",
    "* read data files from disk\n",
    "* practice importing libraries \n",
    "* practice exploring data \n",
    "  * use data frames \n",
    "  * plot data frames\n",
    "* visualize data using various representations (plots)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f150c0",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "In this tutorial, we are going to play around with loading some existing data on a file from disk and then visualizing the distribution of values in the data. Data can be complex and interrelated but, ultimately, a data set is composed of *variables* that can take on *values*.\n",
    "\n",
    "An important first step in analyzing data is often to see how those values are *distributed* – that is, to answer questions like\n",
    "\n",
    "* what is the range of values (and does that range make sense)?\n",
    "* are some values more common than others?\n",
    "* is there a \"typical\" value? Or is there more than one typical value?\n",
    "* are all the data near the \"typical\" value, or are they all very different?\n",
    "* can we describe the data succinctly using a known *distribution*?\n",
    "  - do the data come from an approximately *Gaussian* (or *Normal*) distribution?\n",
    "  - if not, do they come from some other known distribution (or are they just crazy)?\n",
    "* Are two (or more) distributions the...\n",
    "  - same for all practical intents and purposes?\n",
    "  - different looking enough for further investigation?\n",
    " \n",
    "The above are all great questions that it is very important to try to answer as soon as possible after being handed a new dataset. As soon as we start working with new data, it is best practice to spend some good amount of time *describing the data*, that is, characterizing the basic properties the distribution of data. This will ultimately save us time down the road in a project. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9171c593",
   "metadata": {},
   "source": [
    "There are various fancy ways to do this, but the first step, and often the only necessary step, is to just *look at the data!* So, let's do that now!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c8b8de",
   "metadata": {},
   "source": [
    "The distribution plots we'll play with today are:\n",
    "\n",
    "* [Histograms](https://en.wikipedia.org/wiki/Histogram)\n",
    "* [Kernel Density Estimate (KDEs)](https://en.wikipedia.org/wiki/Kernel_density_estimation) plots\n",
    "* [Emperical Cumulative Density Estimate (ECDEs)](https://en.wikipedia.org/wiki/Empirical_distribution_function) plots\n",
    "* [Categorical or Strip plots](https://en.wikipedia.org/wiki/Dot_plot_(statistics)\n",
    "* [Violin Plots](https://en.wikipedia.org/wiki/Violin_plot)\n",
    "* [Boxplots](https://en.wikipedia.org/wiki/Box_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3b8606",
   "metadata": {},
   "source": [
    "Don't worry, we'll unpack these in turn. But they all have something in common; they all attempt to communicate the same thing – *how are the data values distributed* or *what do the distributions of data values look like?* – but do so in ways the emphasize different features and show different levels of detail."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bce2267",
   "metadata": {},
   "source": [
    "### Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b5cb73",
   "metadata": {},
   "source": [
    "#### As always, we need to import some \"data science-y\" libraries\n",
    "\n",
    "As experienced in Tutorial 0001, python require importing the *libraries* needed for the work. This is a bit tricky at the beginning as beginners do not know what libraries contains and do. So, all this at the beginning can appear a bit confusing, but later on as your experience will grow during the semester the role of each library in your work will become more clear, simpler.\n",
    "\n",
    "This class will cover the four fundamental libraries for data science in Python:\n",
    "\n",
    "* [numpy](https://numpy.org/) to generate and manipulate numbers\n",
    "* [pandas](https://pandas.pydata.org/) for reading, plotting and storing advanced data orbjects. Heareafter, we will using to read data saved in a file on your computer's hard drive. The operarions to read and write files from disk are generally referred to as  `i/o` (i.e., `i`nput/`o`utput file operations) \n",
    "* [matplotlib](https://matplotlib.org/) used to make simple plots \n",
    "* [seaborn](https://seaborn.pydata.org/) to plot more complex datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c64d7d",
   "metadata": {},
   "source": [
    "#### Import `numpy`\n",
    "The first libray we import is called `numpy`. We import it using the shortname `np`. Python programmers import libraries using nicknames. This helps making the code sorter when a library is used. For example, to use a command  `arange()` available in `numpy` we would need to use the following line of code `numpy.arange()`, using the nickname `np` the code shortens to `np.arange()`. Nicknames are standardized in python, each libray is geenrally called with a specific nickname. Ok, let's import `numpy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae61c607",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284065db",
   "metadata": {},
   "source": [
    "#### Import `pandas`\n",
    "\n",
    "After `numpy`, we import anohter major library, commonly used in data science applications: `pandas`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678f4017",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2d9f06",
   "metadata": {},
   "source": [
    "#### Import `seaborn`\n",
    "\n",
    "`seaborn` is one of the most used libraries for data visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7c48c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3412ed7f",
   "metadata": {},
   "source": [
    "#### Import `matplotlib`'s `pyplot`\n",
    "\n",
    "After `seaborn`, we import anohter major library, commonly used in data science applications: `pyplot`. Note that `pyplot` is part of the larger library called `matplotlib`. So, here we are importing a sub-module, a smaller library part of a larger library. The syntax goes as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b588049",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e010cad8",
   "metadata": {},
   "source": [
    "$\\color{blue}{\\text{Answer the following question:}}$\n",
    "\n",
    "(1) What is the nickname used for `pyplot`? [Enter answer here]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b8949d",
   "metadata": {},
   "source": [
    "#### Read a dataset saved in a comma separated values dataset (`.csv`)\n",
    "\n",
    "The code, hereafter, uses `pandas` (`pd`) to directly read a `.csv` (comma separated value file). `Pandas` comes with a `csv` file reader. The reader can be called directly, as all the functions of `python`'s libraries are called, using the `<library_name><DOT><function_name>` notation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7a49db",
   "metadata": {},
   "outputs": [],
   "source": [
    "myDataFromFile = pd.read_csv(\"datasets/007DataFile.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5343ddf",
   "metadata": {},
   "source": [
    "$\\color{blue}{\\text{Answer the following questions:}}$\n",
    "\n",
    "In the line of code above, what is the:\n",
    "\n",
    " - name of the library used to load the file?  [Enter answer here]\n",
    " - name of the `pandas` function we use to read the data file?  [Enter answer here]\n",
    " - data file name?  [Enter answer here]\n",
    " - name of the variable used to store the file?  [Enter answer here]\n",
    " - name of the folder containing the data file?  [Enter answer here]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d13174",
   "metadata": {},
   "source": [
    "#### Now let's make sure we read something that looks okay\n",
    "\n",
    "We can use the built-in function `display` to take a look at the data. What is inside this file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5521f302",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(myDataFromFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a2d320",
   "metadata": {},
   "source": [
    "Note that this data frame has two columns, but one of them is not numeric. It is a *grouping variable* that is stored as a text *string* rather than as a number. This type of data is refered to as ['*tidy*'](https://en.wikipedia.org/wiki/Tidy_data).\n",
    "\n",
    "The same data could have stored in two columns, an \"A\" column and a \"B\" column. This kind of data set is 'untidy', and we have already encountered such data (the freezer data). Untidy data is not necessarily evil or anything; for the freezer data, the same variable (temperature) was measured over time, so it actually made sense to have rows represent time points, and the freezers in the columns. \n",
    "\n",
    "But a big advantage of tidy data is that it lets us more easily segregate data by the grouping variable(s). In fact, a big part of data science is actually \"*data wrangling*\", much of which involves making messy data into a tidy form for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bb0609",
   "metadata": {},
   "source": [
    "$\\color{blue}{\\text{Answer the following question:}}$\n",
    "\n",
    " - What are the dimensions (the size) of the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9526b7f",
   "metadata": {},
   "source": [
    "### Data visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d824f6d8",
   "metadata": {},
   "source": [
    "And now for the fun way of looking at data...\n",
    "as visuals!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bb37a3",
   "metadata": {},
   "source": [
    "The seaborn library (which we imported as `sns`) is an advanced plotting library (we will learn more about it later on!). `Seaborn` is advanced because it takes care of many of the plotting details for us, and most of its commands make pretty good looking plots off the shelf (without much work).\n",
    "\n",
    "So let's take seaborn out for a ride!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebb1f6f",
   "metadata": {},
   "source": [
    "#### Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac54aaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(myDataFromFile, x=\"Value\", hue=\"Group\", kind=\"hist\", alpha=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5077bb1b",
   "metadata": {},
   "source": [
    "Note what seaborn did here in a simple call. \n",
    "\n",
    "Here, we made a single call to `seaborn.displot()`, which is short for *distribution plot*. In the three arguments to the call, we \n",
    "\n",
    " 1. told `seaborn.displot()` what data frame to use,\n",
    " 2. mapped the *Value* variable to the `x axis` of the plot and,  \n",
    " 3. mapped the *Group* variable the color of the bars. \n",
    " \n",
    "The function we used was `seaborn.displot()` did a lot of stuff automatically for us: it defaulted to a *histogram* to show the data, picked the width of the binds for the histograms and the specific colors to use (orange & blue – go Gators!), labeled the `x` and `y` axes appropriately, and even made a legend for us! We can customize all of these things of course, but it's nice to have a command like `displot()` that makes a plot with decent defaults."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57435bf3",
   "metadata": {},
   "source": [
    "#### How can we learn more about how displot works?\n",
    "\n",
    "In python you can add a question mark, `?`, at the end of a command to return the functionality of the command. Below the call to show the functionality of `seaborn` `displot` (be ready, this is pretty exhaustive of a command! Also, in some versions of Jupyter the help returned by the `?` will display in a new frame that will need to be closed by clicking the [x]):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffeb544",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9d5174",
   "metadata": {},
   "source": [
    "$\\color{blue}{\\text{Answer the following question:}}$\n",
    "\n",
    " - Write in the cell below the command to show the functionality of `pandas` `read_csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a30e322",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f720127",
   "metadata": {},
   "source": [
    "#### Kernel Density Estimate (KDE) plots\n",
    "\n",
    "Histograms, by definition, are *discrete*: they divide the range of data values into discrete values defined by *bins*, and then count the number of observations in each bin, and then maps these counts to the `y` axis. \n",
    "\n",
    "Data, however, are often *continuous*, with no actual sharp transitions across (arbitrary) bin boundaries. So it would be nice to represent the data in a way reflects the underlying smoothness. One such plot is called a *Kernel Density Estimate* or *KDE* plot. We won't go too deeply under the hood of a KDE plot (calculus required!) but it essentially takes a histogram and blurs it to yield a continuous function (just like if you blur your eyes a sharp point becomes a continuous blob).\n",
    "\n",
    "All we have to do to make a KDE plot (without calculus!) is to tell `seaborn.displot()` that that's what we want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c548673a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(myDataFromFile, x=\"Value\", hue=\"Group\", kind=\"kde\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb89384",
   "metadata": {},
   "source": [
    "As we can see, this plot conveys the data distributions in a perhaps cleaner and more visually appealing way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fc48bc",
   "metadata": {},
   "source": [
    "We can also play around with the appearance of the plot by adding optional arguments to `seaborn.displot()`. For example, we can fill in the areas under the curves, and make the fill transparent so we can see one curve through the other:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c91d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(myDataFromFile, x=\"Value\", hue=\"Group\", kind=\"kde\", fill=True, alpha=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740f199b",
   "metadata": {},
   "source": [
    "The argument `fill` is self-explainatory, and `alpha`, for whatever reason, is the universal variable for \"transparency\" in computer graphics. It always ranges from 0 to 1, with 1 being opaque and 0 being invisible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdfea5c",
   "metadata": {},
   "source": [
    "This is the part where you Google and play around and see what other ways you can change the appearance of our plot!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39483f3a",
   "metadata": {},
   "source": [
    "#### So which is better, the histogram or the KDE plot?\n",
    "\n",
    "Well, one answer is \"Why choose when you can have both?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebac299",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(myDataFromFile, x=\"Value\", hue=\"Group\", kind=\"hist\", kde=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7089bf50",
   "metadata": {},
   "source": [
    "But the better answer is that it depends. Both type of plot can be misleading. \n",
    "\n",
    "For example, a histogram can have too many bins:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8a0827",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(myDataFromFile, x=\"Value\", hue=\"Group\", kind=\"hist\", bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d808ebd5",
   "metadata": {},
   "source": [
    "Or too few:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffd51bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(myDataFromFile, x=\"Value\", hue=\"Group\", kind=\"hist\", bins=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2e705f",
   "metadata": {},
   "source": [
    "---\n",
    "#### Pro tip! \n",
    "If you have a sense of what represents a meaningful change in your data values, it can be more intuitive to adjust `binwidth` instead of `bins`. Try it!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ee9de0",
   "metadata": {},
   "source": [
    "Similarly, a KDE plot can be too smooth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1bceca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(myDataFromFile, x=\"Value\", hue=\"Group\", kind=\"kde\", bw_adjust=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a8974d",
   "metadata": {},
   "source": [
    "Note. How in the above cell we set the parameter `bw_adjust` to 3. Roughly speaking, this paramter sets the number of \"values\" the KDE will average over when deciding where to plot the lines for the the distribution. I feel like this plot is lying about the B distribution, making it look like the population is a perfect normal distribution when it may not be.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad0d71e",
   "metadata": {},
   "source": [
    "They can also be too bumpy, defeating the very point of the KDE plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6d83d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(myDataFromFile, x=\"Value\", hue=\"Group\", kind=\"kde\", bw_adjust=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a2ea34",
   "metadata": {},
   "source": [
    "Assuming the data are roughly normal (Gaussian), and it's reasonable to assume the population is normally distributed, and all else being equal, I tend to prefer KDE plots over histograms. I think they're prettier. That being said, I would never try to sell someone a KDE plot without 1) looking histograms myself to inspect the data and 2) having a histogram loaded into the chamber in case anybody asks. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a340a323",
   "metadata": {},
   "source": [
    "---\n",
    "##### Note on KDE plots:\n",
    "The *kernel density estimate* uses a mathematical function called the kernel - often a normal distribution - to \"blur\" the data via an operation akin to *convolution*. The 'bw_adjust' argument adjusts the *bandwidth* of the kernel. The larger the bandwidth, the smoother the plot will appear; the smaller, the more wiggly.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c88df3f",
   "metadata": {},
   "source": [
    "#### Empirical Cumulative Density Estimate plots\n",
    "\n",
    "Another usefull way to look at distributions is with the *Empirical Cumulative Density Estimate* plot or *ECDF*. It plots, for each value on the x axis, the proportion of the data that fall to left of that value. It hence goes from 0.0 on the left (just below the very smallest data value) to 1.0 on the right (just above the very highest data value). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838a4f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(myDataFromFile, x=\"Value\", hue=\"Group\", kind=\"ecdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f993dd",
   "metadata": {},
   "source": [
    "Visually, you can see that - calculus alert! - the *ECDF* is essentially the integral of the *KDE*. In fact, let's actually plot the intergral of our first KDE plot from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002d2c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(myDataFromFile, x=\"Value\", hue=\"Group\", kind=\"kde\", cumulative=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085b7a02",
   "metadata": {},
   "source": [
    "Sweet!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b34b952",
   "metadata": {},
   "source": [
    "In all the \"goldilocks\" plots, we can clearly see the relative shift in the two distributions (median or mean) in addition to the different widths (standard deviations)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb62f3c",
   "metadata": {},
   "source": [
    " The difference in medians or means is shown by the relative shift of the two distributions in all the plots. In the *ECDF*, the value on the x axis corresponding to midpoint on the y axis – at 0.5 – is by definition the median.\n",
    " \n",
    " The difference in standard deviations in the *KDE* and histogram is shown by the relative widths or \"fatnesses\" of the two distributions, whereas in the *ECDF*, it is given by the steepnesses (slopes) of the curve.\n",
    " \n",
    " Which type of plot is better is both situational and a matter of taste; I like the *histogram* and *KDE* for appreciating the \"vibe\" of distributions, but the *ECDF* can be better at revealing small but systematic shifts in the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279b6c08",
   "metadata": {},
   "source": [
    "Seaborn also provides some built-in themes to change the overall appearance of plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2b1183",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.set_style(\"darkgrid\")\n",
    "sns.displot(myDataFromFile, x=\"Value\", hue=\"Group\", kind=\"ecdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd49c5d",
   "metadata": {},
   "source": [
    "That's nice! But, personally, I'd like more ticks/gridlines on the y axis and, since 0.5 corresponds to the median, it would be nice to have a gridline exactly there. To do this, we'll delve into the \"lower level\" `matplotlib` functions. In this particular case, we'll use the `matplotlib.pyplot.yticks()` function to make gridlines where we want them, and we'll use `np.arange()` to make the exact values for the gridlines. And remember, we imported `matplotlib.pyplot` as `plt`, so that will save us a little typing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e29508",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(myDataFromFile, x=\"Value\", hue=\"Group\", kind=\"ecdf\")\n",
    "myTickMarks = np.arange(0, 1, 0.1)\n",
    "plt.yticks(myTickMarks);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff4d7e2",
   "metadata": {},
   "source": [
    "Here, we put the tick values in a new variable we created, and then passed that variable to `plt.yticks`. We could have done this all in one go if we wanted:\n",
    "`plt.yticks(np.arange(0, 1, 0.1))`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759eec63",
   "metadata": {},
   "source": [
    "I always want to read `arange()` as \"arrange\", but it's really \"a range\", as in \"a range of values\" – the three arguments to `np.arange()` are the minimum, maximum, and step size of the range. Now we can literally see that the two medians are about 0 and 1. Since the distributions are \"normalish\" or roughly Gaussian, these correspond to the means as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff48f3b",
   "metadata": {},
   "source": [
    "(obviously, there is a corresponding call to set the x ticks...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5403048f",
   "metadata": {},
   "source": [
    "#### Categorical or strip plots\n",
    "\n",
    "One simple thing we can do is to directluy look at all the data points, split by category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654f0dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data=myDataFromFile, x=\"Group\", y=\"Value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca16363d",
   "metadata": {},
   "source": [
    "The command `seaborn.catplot()` makes a *categorical plot*, i.e. a plot with a categorical x axis and a numerical y axis. Notice that `seaborn.catplot()` jitters the data points horizontally so you can see more of them without occlusion. This type of plot is also called a *strip plot*.\n",
    "\n",
    "Also notice that our theme has been applied to every plot since early on in this tutorial (actually on cell `[14]`), we called `sns.set_style(\"darkgrid\")`. This sets up a specific type of style for the plot and the style will be kept for all plots following the `set_style` call."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439d10bb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2681a228",
   "metadata": {},
   "source": [
    "##### Quick quiz! \n",
    "Can you make the data points transparent so that data points on top of one another appear as darker clusters?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b2a70e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d436132",
   "metadata": {},
   "source": [
    "#### Violin plots\n",
    "\n",
    "It's worth reiterating and emphasizing that, in the categorical plot, we changed the mapping of the variables. In the previous plots, both disributions plotted on a single coordinate system, and the categorical variable was mapped to a color. This is great for one and sometimes two distributions. But with multiple distributions, i.e. multiple values of a categorical grouping variable, plots can get busy and hard to read. Mapping the grouping variable to position on the x axis is a great solution, as it pulls the distributions apart so they can be visually compared more easily.\n",
    "\n",
    "Another kind of plot that maps a grouping variable to the x axis is a *violin plot*. Here's one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a733dfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.violinplot(data=myDataFromFile, x=\"Group\", y=\"Value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3beed455",
   "metadata": {},
   "source": [
    "The violin plot is essentially a KDE plot in which the distributions are flipped on their sides, separated along the x axis, and plotted along with a mirror image. Sometimes the actual data are plotted as well. As with all plots, there are various things we can tinker with (Google is your friend!). For example, we can plot the data values as \"sticks\" instead of points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe06f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.violinplot(data=myDataFromFile, x=\"Group\", y=\"Value\", inner=\"stick\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eab4f26",
   "metadata": {},
   "source": [
    "#### Boxplots\n",
    "\n",
    "Notice that both histograms and categorical (strip) plots attempt to show the data directly, whereas KDE and violin plots abstract the data a little by trying to estimate the smooth distribution underlying the data. We can do a further extraction by plotting some summary numbers instead of the data themselves using a *box plot*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18aa9f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=myDataFromFile, x=\"Group\", y=\"Value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60936f7e",
   "metadata": {},
   "source": [
    "A boxplot shows 5 summary numbers. The *median* is shown by a horizontal line. The upper and lower bounds of the *interquartile range* or *IQR* are shown by a box. Finally, values at 1.5x the IQR above and below the median are plotted as *whiskers* (boxplots are sometimes called box-and-whiskers plots). Any data points falling outside the whiskers plotted individually as potential outliers.\n",
    "\n",
    "Sometimes it is helpful to combine plots to show both the data and some summary numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba0f463",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=myDataFromFile, x=\"Group\", y=\"Value\")\n",
    "sns.stripplot(data=myDataFromFile, x=\"Group\", y=\"Value\", alpha = 0.42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9ec752",
   "metadata": {},
   "source": [
    "We can \"check our work\" by summarizing the data and comparing the percentiles with what's shown by are boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d62e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "myDataFromFile.groupby(\"Group\").describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7498d7",
   "metadata": {},
   "source": [
    "Looks good!\n",
    "\n",
    "But – wait! – let's unpack the call above a little bit. As we've already seen, data frames in pandas \"know\" how to do things. We saw last time that they know how to make a boxplot of themselves, for example.\n",
    "\n",
    "In the call `myDataFromFile.groupby(\"Group\").describe()`, the `myDataFromFile.groupby(\"Group\")` part tells the data frame to group itself by the \"Group\" variable. And then the `.describe()` tells it to describe itself for us. \n",
    "If you've used R and the tidyverse, then this is roughly equivalent to \n",
    "\n",
    "```\n",
    "myDataFromFile %>%\n",
    "    group_by(\"Group\") %>%\n",
    "    summarize()\n",
    "```\n",
    "\n",
    "\n",
    "If we have our current data frame make a boxplot of itself..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d404fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "myDataFromFile.boxplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b13ec31",
   "metadata": {},
   "source": [
    "... it's not super useful because it looks at the data, sees only one numeric variable, and makes a boxplot of that variable (from both groups). But since it turns out that data frames know how to group themselves, maybe we can group and then boxplot, just like we grouped and then described above. Let's try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486b7b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "myDataFromFile.groupby(\"Group\").boxplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d2bce9",
   "metadata": {},
   "source": [
    "Nice! I prefer the seaborn version, but this is a nice tool to have in out toolbelt.\n",
    "\n",
    "Okay, so now we know how to make a number of *distribution* plots in python, and know a little bit about how to work with data that have a grouping variable. Sam would be proud!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d840b54",
   "metadata": {},
   "source": [
    "$\\color{blue}{\\text{Final Report for this Tutorial.}}$\n",
    "\n",
    " - create a new repository under your user account on [github.com/yourUserName](github.com/yourUserName).\n",
    " - clone the repository locally on your computer (pick a smart folder to do so, say, `~/git` or `~/code`)\n",
    " - move the file of jupyter notebookd for this tutorial in the folder of the repository cloned above. This will require using a combination of commands such as `mv` and `cp` and `cd` and `ls` (you can also do this by use your mouse, but make sure you are copying inside the proper ).\n",
    " - use `git add [file name]` Add the file you edited for this tutorial to the repository\n",
    " - use `git commit -am \"Your message here\"` to commit the file to the repository\n",
    " - push the local repository with the changes and the newly added file to the cloud using `git push [repository name]`\n",
    " - Submit the URL to the github repository on Canvas\n",
    " \n",
    " Note. Now on, the above is going to be required for every tutorial. We will always ask for you to report the URL of the tutorial with all the operations performed by you and the answers to the questions visible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97955d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
